#!/usr/bin/env python3
# Convert a coreos-assembler build into a "release.json"
# Originally from https://github.com/coreos/fedora-coreos-releng-automation/blob/master/coreos-meta-translator/trans.py
# See also https://github.com/coreos/fedora-coreos-tracker/blob/master/Design.md#release-streams


from argparse import ArgumentParser
import json
import os

from cosalib.builds import Builds


def ensure_dup(inp, out, inp_key, out_key):
    '''
    If the out dictionary does not contain a value for out_key update it
    to be equal to the inp dictionaries inp_key value, if it does exist
    ensure the values are equal between the two dictionaries
    '''
    if out.get(out_key, None) is None:
        out[out_key] = inp.get(inp_key)
    if out.get(out_key) != inp.get(inp_key):
        raise Exception("Input Files do not appear to be for the same release")


def url_builder(stream, version, arch, path):
    return f"https://builds.coreos.fedoraproject.org/prod/streams/{stream}/builds/{version}/{arch}/{path}"


def get_extension(path, modifier, arch):
    return path.rsplit(f'{modifier}.{arch}')[1][1:]


parser = ArgumentParser()
parser.add_argument("--workdir", help="cosa workdir")
parser.add_argument("--build-id", help="build id")
parser.add_argument("--output", help="Output to file; default is build directory")
args = parser.parse_args()

# FIXME: Remove this once https://github.com/coreos/fedora-coreos-pipeline/ is ported
# not to pass --workdir (it always uses `.` anyways)
if args.workdir not in (None, '.'):
    os.chdir(args.workdir)


def gather_buildmeta_from_workdir():
    builds = Builds()
    # default to latest build if not specified
    if args.build_id:
        buildid = args.build_id
    else:
        buildid = builds.get_latest()
    print(f"Creating release.json for build {buildid}")
    base_builddir = f"builds/{buildid}"
    arches = builds.get_build_arches(buildid)

    return (base_builddir, [os.path.join(base_builddir, arch, "meta.json") for arch in arches])


(builddir, archbuilds) = gather_buildmeta_from_workdir()
out = {}
# Default to writing into the builddir for now
if args.output is None:
    args.output = os.path.join(builddir, "release.json")
# If any existing data, inherit it
if os.path.exists(args.output):
    with open(args.output, 'r') as w:
        out = json.load(w)
        print(f"Using existing release file {args.output}")

for f in archbuilds:
    with open(f, 'r') as w:
        input_ = json.load(w)

        arch = input_.get("coreos-assembler.basearch")

        ensure_dup(input_, out, "buildid", "release")
        ensure_dup(input_.get('coreos-assembler.container-config-git'), out, 'branch', 'stream')

        def artifact(i):
            base_url = url_builder(out.get('stream'), out.get('release'), arch, i.get('path'))
            return {
                "location": base_url,
                "signature": "{}.sig".format(base_url),
                "sha256": i.get("sha256")
            }

        print(f"{out['stream']} stream")
        print(f"  {arch} images:")
        # build the architectures dict
        arch_dict = {"media": {}}
        ensure_dup(input_, arch_dict, "ostree-commit", "commit")
        platforms = ["aliyun", "aws", "azure", "digitalocean", "exoscale", "gcp", "ibmcloud", "metal", "openstack", "qemu", "vmware", "vultr"]
        for platform in platforms:
            if input_.get("images", {}).get(platform, None) is not None:
                print(f"   - {platform}")
                i = input_.get("images").get(platform)
                ext = get_extension(i.get('path'), platform, arch)
                arch_dict['media'][platform] = {
                    "artifacts": {
                        ext: {
                            "disk": artifact(i)
                        }
                    }
                }

        # AMI specific additions
        if input_.get("amis", None) is not None:
            arch_dict["media"]["aws"] = arch_dict["media"].get("aws", {})
            arch_dict["media"]["aws"]["images"] = arch_dict["media"]["aws"].get("images", {})
            for ami_dict in input_.get("amis"):
                arch_dict["media"]["aws"]["images"][ami_dict["name"]] = {
                    "image": ami_dict["hvm"]
                }

        # GCP specific additions
        if input_.get("gcp", None) is not None:
            arch_dict["media"]["gcp"] = arch_dict["media"].get("gcp", {})
            arch_dict["media"]["gcp"]["image"] = arch_dict["media"]["gcp"].get("image", {})
            arch_dict["media"]["gcp"]["image"].update(input_.get("gcp", {}))
            arch_dict["media"]["gcp"]["image"]["name"] = arch_dict["media"]["gcp"]["image"].pop("image")
            # remove the url as we haven't decided to expose that information publicly yet
            arch_dict["media"]["gcp"]["image"].pop("url")

        # metal specific additions
        arch_dict["media"]["metal"] = arch_dict["media"].get("metal", {})
        arch_dict["media"]["metal"]["artifacts"] = arch_dict["media"]["metal"].get("artifacts", {})
        i = input_.get("images", {}).get("metal4k", None)
        if i is not None:
            # the 4k image is kinda weird; we want it at the same level as e.g.
            # the regular 512b image, which normally is under `raw.xz`
            ext = get_extension(i['path'], 'metal4k', arch)
            arch_dict["media"]["metal"]["artifacts"][f"4k.{ext}"] = {
                "disk": artifact(i)
            }
        i = input_.get("images", {}).get("iso", None)
        if i is not None:
            arch_dict["media"]["metal"]["artifacts"]["installer.iso"] = {
                "disk": artifact(i)
            }
        i = input_.get("images", {}).get("kernel", None)
        if i is not None:
            arch_dict["media"]["metal"]["artifacts"].setdefault("installer-pxe", {})["kernel"] = artifact(i)
        i = input_.get("images", {}).get("initramfs", None)
        if i is not None:
            arch_dict["media"]["metal"]["artifacts"].setdefault("installer-pxe", {})["initramfs"] = artifact(i)
        i = input_.get("images", {}).get("live-iso", None)
        if i is not None:
            arch_dict["media"]["metal"]["artifacts"]["iso"] = {
                "disk": artifact(i)
            }
        i = input_.get("images", {}).get("live-kernel", None)
        if i is not None:
            arch_dict["media"]["metal"]["artifacts"].setdefault("pxe", {})["kernel"] = artifact(i)
        i = input_.get("images", {}).get("live-initramfs", None)
        if i is not None:
            arch_dict["media"]["metal"]["artifacts"].setdefault("pxe", {})["initramfs"] = artifact(i)
        i = input_.get("images", {}).get("live-rootfs", None)
        if i is not None:
            arch_dict["media"]["metal"]["artifacts"].setdefault("pxe", {})["rootfs"] = artifact(i)

        # if architectures as a whole or the individual arch is empty just push our changes
        if out.get('architectures', None) is None or out['architectures'].get(arch, None) is None:
            oa = out.get('architectures', {})
            oa[arch] = arch_dict
            out['architectures'] = oa
        # else check media warning if key present, appending if not
        else:
            out_arch = out['architectures'][arch]
            for media_type, val in arch_dict.get('media').items():
                if media_type not in out_arch['media']:
                    out['architectures'][arch]['media'].update({media_type: val})
                elif val == out_arch['media'][media_type]:
                    continue
                else:
                    raise Exception("differing content detected for media type '{}'".format(media_type))

with open(args.output, 'w') as w:
    json.dump(out, w)
    print(f"Successfully wrote release file at {args.output}")
