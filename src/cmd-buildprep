#!/usr/bin/env python3
# NOTE: PYTHONUNBUFFERED is set in cmdlib.sh for unbuffered output
#
# Fetches the bare minimum from external servers to create the next build. May
# require configured AWS credentials if bucket and objects are not public.

import argparse
import os
import subprocess
import sys
import requests
import botocore
import boto3
import shutil

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from cmdlib import load_json, rm_allow_noent  # noqa: E402


def main():
    args = parse_args()

    if args.url.startswith("s3://"):
        fetcher = S3Fetcher(args.url)
    elif args.url.startswith("http://") or args.url.startswith("https://"):
        fetcher = HTTPFetcher(args.url)
    elif args.url.startswith("file://") or args.url.startswith("/"):
        fetcher = LocalFetcher(args.url)
    else:
        raise Exception("Invalid scheme: only file://, s3://, and http(s):// supported")

    builds = []
    if fetcher.exists('builds.json'):
        builds = fetcher.fetch_json('builds.json')['builds']

    if len(builds) == 0:
        print("Remote has no builds!")
        return

    buildid = builds[0]
    os.makedirs(f'builds/{buildid}', exist_ok=True)
    for f in ['meta.json', 'ostree-commit-object']:
        fetcher.fetch(f'{buildid}/{f}')

    # and finally the symlink
    rm_allow_noent('builds/latest')
    os.symlink(buildid, 'builds/latest')

    # also nuke the any local matching OStree ref, since we want to build on
    # top of this new one
    buildmeta = load_json('builds/latest/meta.json')
    if 'ref' in buildmeta and os.path.isdir('tmp/repo'):
        subprocess.check_call(['ostree', 'refs', '--repo', 'tmp/repo',
                               '--delete', buildmeta['ref']],
                              stdout=subprocess.DEVNULL)


def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument("url", metavar='URL',
                        help="URL from which to fetch metadata")
    return parser.parse_args()


class Fetcher(object):

    def __init__(self, url_base):
        self.url_base = url_base

    def fetch(self, path, dest=None):
        # if no specific dest given, assume it's a path under builds/
        if dest is None:
            dest = f'builds/{path}'
        # NB: `urllib.parse.urljoin()` does not do what one thinks it does.
        # Using `os.path.join()` is a hack, but eh... we're not planning to run
        # on Windows anytime soon.
        url = os.path.join(self.url_base, path)
        print(f"Fetching: {url}")
        self.fetch_impl(url, dest)
        return dest

    def fetch_json(self, path):
        return load_json(self.fetch(path))

    def exists(self, path):
        url = os.path.join(self.url_base, path)
        return self.exists_impl(url)


class HTTPFetcher(Fetcher):

    def __init__(self, url_base):
        super().__init__(url_base)

    def fetch_impl(self, url, dest):
        # notice we don't use `stream=True` here; the stuff we're fetching for
        # now is super small
        with requests.get(url) as r:
            r.raise_for_status()
            with open(dest, mode='wb') as f:
                f.write(r.content)

    def exists_impl(self, url):
        with requests.head(url) as r:
            if r.status_code == 200:
                return True
            if r.status_code == 404:
                return False
            raise Exception(f"Received rc {r.status_code} for {url}")


class S3Fetcher(Fetcher):

    def __init__(self, url_base):
        super().__init__(url_base)

    def fetch_impl(self, url, dest):
        subprocess.check_call(['aws', 's3', 'cp', url, dest],
                              stdout=subprocess.DEVNULL)

    def exists_impl(self, url):
        assert url.startswith("s3://")
        bucket, key = url[len("s3://"):].split('/', 1)
        s3 = boto3.client('s3')
        # sanity check that the bucket exists and we have access to it
        s3.head_bucket(Bucket=bucket)
        try:
            s3.head_object(Bucket=bucket, Key=key)
        except botocore.exceptions.ClientError as e:
            if e.response['Error']['Code'] == '404':
                return False
            raise e
        return True


class LocalFetcher(Fetcher):

    def __init__(self, url_base):
        if url_base.startswith("file://"):
            url_base = url_base[len("file://"):]
        super().__init__(url_base)

    def fetch_impl(self, url, dest):
        shutil.copyfile(url, dest)

    def exists_impl(self, url):
        return os.path.exists(url)


if __name__ == '__main__':
    sys.exit(main())
