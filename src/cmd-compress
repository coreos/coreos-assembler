#!/usr/bin/env python3
# NOTE: PYTHONUNBUFFERED is set in the entrypoint for unbuffered output
#
# Compresses all images in a build.

import os
import re
import sys
import math
import json
import shutil
import argparse

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from cosalib.builds import Builds
from cosalib.cmdlib import (
    rm_allow_noent,
    run_verbose,
    sha256sum_file,
    write_json)

DEFAULT_COMPRESSOR = 'gzip'

parser = argparse.ArgumentParser()
parser.add_argument("--build", help="Build ID")
parser.add_argument("--artifact", default=[], action='append',
                    help="Only compress given image ARTIFACT", metavar="ARTIFACT")
parser.add_argument("--compressor",
                    choices=['xz', 'gzip'],
                    default=DEFAULT_COMPRESSOR,
                    help=f"Compressor to use, default is {DEFAULT_COMPRESSOR}")
parser.add_argument("--fast", action='store_true',
                    help="Override compression to `gzip -1`")
args = parser.parse_args()

# that's the tool default
gzip_level = 6
if args.fast:
    args.compressor = 'gzip'
    gzip_level = 1

# find extension for --compressor
ext_dict = {'xz': '.xz', 'gzip': '.gz'}
ext = ext_dict[args.compressor]

builds = Builds()

# default to latest build if not specified
if args.build:
    build = args.build
else:
    build = builds.get_latest()

print(f"Targeting build: {build}")

# Don't compress certain images
imgs_to_skip = ["ostree", "live-iso", "vmware", "live-initramfs", "live-kernel", "live-rootfs"]


def get_cpu_param(param):
    with open(f'/sys/fs/cgroup/cpu/cpu.{param}') as f:
        return int(f.read().strip())


# XXX: should dedupe this with logic in cmdlib and put in the shared lib
def xz_threads():
    with open("/proc/1/cgroup") as f:
        in_k8s = re.search(r'.*kubepods.*', f.read())
    if in_k8s:
        # see similar code in OpenJKD HotSpot:
        # https://hg.openjdk.java.net/jdk/jdk/file/7b671e6b0d5b/src/hotspot/os/linux/osContainer_linux.cpp#l595
        quota = get_cpu_param('cfs_quota_us')
        period = get_cpu_param('cfs_period_us')
        # are k8s limits enforced?
        if quota != -1 and period > 0:
            return math.ceil(quota / period)
    return 0  # no limits, let xz choose what it wants


def compress_one_builddir(builddir):
    print(f"Compressing: {builddir}")
    buildmeta_path = os.path.join(builddir, 'meta.json')
    # In the case where we are doing builds for different architectures
    # it's likely not all builds for this arch are local. If the meta.json
    # doesn't exist then return early.
    if not os.path.exists(buildmeta_path):
        print(f"No meta.json exists for {builddir}.. Skipping")
        return False
    with open(buildmeta_path) as f:
        buildmeta = json.load(f)

    tmpdir = 'tmp/compress'
    if os.path.isdir(tmpdir):
        shutil.rmtree(tmpdir)
    os.mkdir(tmpdir)

    # Note we mutate the build dir in place, similarly to the buildextend
    # commands.  One cool approach here might be to `cp -al` the whole build
    # dir, mutate it, then RENAME_EXCHANGE the two... though it doesn't seem
    # Python exposes it yet so that'd require some hacking around. For now, we
    # just guarantee that `compress` is idempotent and can resume from
    # failures.

    at_least_one = False

    only_artifacts = None
    if len(args.artifact) > 0:
        only_artifacts = set(args.artifact)

    for img_format, img in buildmeta['images'].items():
        if img_format in imgs_to_skip:
            print(f"Skipping {img_format}")
            continue
        if only_artifacts is not None and img_format not in only_artifacts:
            continue

        file = img['path']
        filepath = os.path.join(builddir, file)
        # check if it's not already compressed, even if with a different
        # compressor (like for GCP, which needs .tar.gz, see:
        # https://github.com/coreos/coreos-assembler/pull/1009)
        if not file.endswith(tuple(ext_dict.values())):
            tmpfile = os.path.join(tmpdir, (file + ext))
            # SHA256 + size for uncompressed image was already calculated
            # during 'build'
            img['uncompressed-sha256'] = img['sha256']
            img['uncompressed-size'] = img['size']
            with open(tmpfile, 'wb') as f:
                if args.compressor == 'xz':
                    t = xz_threads()
                    run_verbose(['xz', '-c9', f'-T{t}', filepath], stdout=f)
                else:
                    run_verbose(['gzip', f'-{gzip_level}', '-c', filepath], stdout=f)
            file_with_ext = file + ext
            filepath_with_ext = filepath + ext
            compressed_size = os.path.getsize(tmpfile)
            img['path'] = file_with_ext
            img['sha256'] = sha256sum_file(tmpfile)
            img['size'] = compressed_size

            # Just flush out after every image type, but unlink after writing.
            # Then, we should be able to interrupt and restart from the last
            # type.
            shutil.move(tmpfile, filepath_with_ext)
            write_json(buildmeta_path, buildmeta)
            os.unlink(filepath)
            at_least_one = True
            print(f"Compressed: {file_with_ext}")
        else:
            # try to delete the original file if it's somehow still around
            rm_allow_noent(filepath[:-3])

    if at_least_one:
        print(f"Updated: {buildmeta_path}")
    return at_least_one


changed = []
for arch in builds.get_build_arches(build):
    builddir = builds.get_build_dir(build, arch)
    changed.append(compress_one_builddir(builddir))

if not any(changed):
    print("All builds already compressed")
