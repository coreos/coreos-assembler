From 056d2fd5a419ab5f5974864b513230d3d133f7cf Mon Sep 17 00:00:00 2001
From: Michael Vogt <michael.vogt@gmail.com>
Date: Wed, 13 Dec 2023 10:07:32 +0100
Subject: [PATCH 2/4] fscache: add FsCache._remove_lru() to remove entries

The FsCache._remove_lru() removes the least recently used entry
from the cache.
---
 osbuild/util/fscache.py | 44 +++++++++++++++++++++++++++++++++++++++++
 1 file changed, 44 insertions(+)

diff --git a/osbuild/util/fscache.py b/osbuild/util/fscache.py
index 58c9a310..21e03f95 100644
--- a/osbuild/util/fscache.py
+++ b/osbuild/util/fscache.py
@@ -1086,6 +1086,50 @@ class FsCache(contextlib.AbstractContextManager, os.PathLike):
             objs.append(FsCacheObjectInfo(name=name, last_used=last_used))
         return sorted(objs, key=lambda obj: obj.last_used)
 
+    def _remove_lru(self):
+        """"Remove the least recently used entry from the cache."""
+        # To avoid having to take a global cache lock the strategy is:
+        # 1. Get list of (object, last_used) sorted from oldest to newest.
+        #    This is racy so we need to take care of that in step(2).
+        # 2. Start with the oldest entry, try to take a write_lock
+        #    (with O_NOATIME to be extra sure that atime information is
+        #    correct). Get the "last_used" (atime) time and compare to what
+        #    we expect in the list. If it diverges the object got load()ed
+        #    while we iterated. Skip it and go to (2) again.
+        # 3. Remove entry, update cache size after the entry is removed.
+        #
+        # Note that there is a risk to get out-of-sync in (3). If the
+        # process dies while removing and before updating the cache
+        # size the cache will be over reported.
+        for name, last_used in self._last_used_objs():
+            # take write lock for the indivdual object
+            rpath = os.path.join(self._dirname_objects, name)
+            rpath_lock = os.path.join(rpath, self._filename_object_lock)
+            # Ideally there would some lock helper instead of the low-level
+            # file manipulation to abstract this a bit more.
+            try:
+                with self._atomic_open(
+                        rpath_lock,
+                        wait=False,
+                        write=True,
+                        # atime carries the "last-used" data so don't alter it
+                        oflags=os.O_EXCL | os.O_NOATIME,
+                ):
+                    if last_used != self._last_used(name):
+                        continue
+                    # This is racy right now. To fix it we need to (atomic)
+                    # rename the "object.info" file in _rm_r_object() to
+                    # something like "object.removing". Then when opening
+                    # the cache scan for leftover "object.removing" files
+                    # and finish the cleanup and update the cache size
+                    # based on the size recorded inside "object.removing".
+                    size = self._calculate_space(self._path(rpath))
+                    self._rm_r_object(rpath)
+                    self._update_cache_size(-size)
+                    return
+            except BlockingIOError:
+                continue
+
     @property
     def info(self) -> FsCacheInfo:
         """Query Cache Information
-- 
2.43.0

