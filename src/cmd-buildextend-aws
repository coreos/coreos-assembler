#!/usr/bin/env python3
# NOTE: PYTHONUNBUFFERED is set in the entrypoint for unbuffered output
#
# An operation that mutates a build by uploading to EC2,
# extending the meta.json with AMI information.
# See doc/aws.md for a bit more information.

import os
import sys
import json
import shutil
import argparse
import subprocess

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from cosalib.builds import Builds
from cosalib.cmdlib import run_verbose, write_json, sha256sum_file, get_basearch

# Parse args and dispatch
parser = argparse.ArgumentParser()
parser.add_argument("--build", help="Build ID")
parser.add_argument("--region", help="EC2 region")
parser.add_argument("--bucket", help="S3 Bucket")
parser.add_argument("--name-suffix", help="Suffix for name")
parser.add_argument("--grant-user", help="Grant user launch permission",
                    nargs="*", default=[])
parser.add_argument("--log-level", help="ore log level")
parser.add_argument("--upload", action='store_true', default=False,
                    help="Upload to AWS")
args = parser.parse_args()

if args.upload:
    for attr in ['region', 'bucket']:
        if getattr(args, attr) is None:
            raise Exception(f"Must provide --{attr} option in order to to upload")

# Identify the builds and target the latest build if none provided
builds = Builds()
if not args.build:
    args.build = builds.get_latest()
print(f"Targeting build: {args.build}")

builddir = builds.get_build_dir(args.build)
buildmeta_path = os.path.join(builddir, 'meta.json')
with open(buildmeta_path) as f:
    buildmeta = json.load(f)

basearch = get_basearch()
base_name = buildmeta['name']
if args.name_suffix:
    ami_name_version = f'{base_name}-{args.name_suffix}-{args.build}'
else:
    ami_name_version = f'{base_name}-{args.build}'
aws_vmdk_name = f'{ami_name_version}-aws.{basearch}.vmdk'
aws_vmdk_path = f"{builddir}/{aws_vmdk_name}"

tmpdir = 'tmp/buildpost-aws'
if os.path.isdir(tmpdir):
    shutil.rmtree(tmpdir)
os.mkdir(tmpdir)


def generate_aws_vmdk():
    img_qemu = os.path.join(builddir, buildmeta['images']['qemu']['path'])
    tmp_img_aws = os.path.join(tmpdir, (ami_name_version + '.qcow2'))
    tmp_img_aws_vmdk = os.path.join(tmpdir, (ami_name_version + '.vmdk'))
    run_verbose(['/usr/lib/coreos-assembler/gf-platformid',
                 img_qemu, tmp_img_aws, 'aws'])
    run_verbose(['qemu-img', 'convert', '-f', 'qcow2', '-O', 'vmdk',
                 tmp_img_aws,
                 '-o', 'adapter_type=lsilogic,subformat=streamOptimized,compat6',
                 tmp_img_aws_vmdk])
    os.unlink(tmp_img_aws)
    checksum = sha256sum_file(tmp_img_aws_vmdk)
    size = os.path.getsize(tmp_img_aws_vmdk)
    os.rename(tmp_img_aws_vmdk, aws_vmdk_path)
    shutil.rmtree(tmpdir)
    buildmeta['images'].update({
        'aws': {
            'path': aws_vmdk_name,
            'sha256': checksum,
            'size': size
        }
    })
    write_json(buildmeta_path, buildmeta)  # update build metadata


def run_ore():
    ore_args = ['ore']
    if args.log_level:
        ore_args.extend(['--log-level', args.log_level])
    ore_args.extend(['aws', 'upload',
                     '--region', args.region,
                     '--bucket', args.bucket,
                     '--ami-name', ami_name_version,
                     '--name', ami_name_version,
                     '--ami-description', f"{buildmeta['summary']} {args.build}",
                     '--file', aws_vmdk_path,
                     '--disk-size-inspect',
                     '--delete-object',
                     '--force'])
    for user in args.grant_user:
        ore_args.extend(['--grant-user', user])
    print("+ {}".format(subprocess.list2cmdline(ore_args)))
    ore_data = json.loads(subprocess.check_output(ore_args))
    # This matches the Container Linux schema:
    # https://stable.release.core-os.net/amd64-usr/current/coreos_production_ami_all.json
    ami_data = {'name': args.region,
                'hvm': ore_data['HVM'],
                'snapshot': ore_data['SnapshotID']}
    buildmeta['amis'] = [ami_data]
    write_json(buildmeta_path, buildmeta)  # update build metadata


# Generate the disk image to be uploaded
if 'aws' not in buildmeta['images']:
    generate_aws_vmdk()
else:
    print('AWS image already built. Skipping image creation')
# Do the upload if asked
if args.upload:
    run_ore()
else:
    print('--upload not passed. Skipping image upload to cloud')
print('buildextend-aws complete!')
